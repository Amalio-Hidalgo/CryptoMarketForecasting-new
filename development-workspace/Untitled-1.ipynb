{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Crypto Volatility Forecasting "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“¦ Imports & Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Utilities \n",
    "import  random, os, pandas as pd, numpy as np\n",
    "import matplotlib.pyplot as plt, datetime as dt\n",
    "import dotenv, os, requests, time\n",
    "\n",
    "# Environment & Dask Client\n",
    "plt.rcParams['figure.figsize'] = (10,4)\n",
    "os.makedirs(\"OutputData\", exist_ok=True)\n",
    "dotenv.load_dotenv(dotenv.find_dotenv(filename=\".env\"))\n",
    "from dask.distributed import Client, LocalCluster\n",
    "\n",
    "# Features \n",
    "import talib\n",
    "\n",
    "# Models\n",
    "from arch import arch_model\n",
    "import statsmodels.api as sm\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ”§ Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key Variables\n",
    "TARGET_COIN = \"ethereum\"\n",
    "BASE_FIAT   = \"usd\"\n",
    "TOP_N       = 10\n",
    "LOOKBACK_DAYS = 365\n",
    "START_DATE = (dt.datetime.now() - dt.timedelta(days=LOOKBACK_DAYS)).strftime(\"%Y-%m-%d\")\n",
    "TIMEZONE = \"Europe/Madrid\"\n",
    "SMA_WINDOWS = (10, 20, 50)\n",
    "EMA_WINDOWS = (10, 20, 50)\n",
    "TRAIN_SPLIT = 0.90\n",
    "# --- GARCH config ---\n",
    "GARCH_SCALE = 100.0\n",
    "GARCH_REFIT_EVERY = 5\n",
    "SEQ_LEN = 7\n",
    "# --- LSTM configuration ---\n",
    "LSTM_UNITS = 64\n",
    "LSTM_EPOCHS = 25\n",
    "LSTM_BATCH = 16\n",
    "# --- Dune API configuration ---\n",
    "DUNE_QUERIES = {\n",
    "    \"economic_security\": 1933076,\n",
    "    \"daily_dex_volume\": 4388,\n",
    "    \"btc_etf_flows\": 5795477,\n",
    "    \"eth_etf_flows\": 5795645,\n",
    "    \"total_defi_users\": 2972,\n",
    "    \"median_gas\": 2981260,\n",
    "}\n",
    "DUNE_API_KEY = os.getenv(\"DUNE_API_KEY\")\n",
    "DUNE_CSV_PATH = \"OutputData/Dune_Metrics.csv\"\n",
    "\n",
    "# --- FRED API configuration ---\n",
    "FRED_API_KEY= os.getenv(\"FRED_API_KEY\")\n",
    "FRED_KNOWN = {\n",
    "    \"VIXCLS\":   \"vix_equity_vol\",            # CBOE VIX (Equity market volatility index)\n",
    "    \"MOVE\":     \"move_bond_vol\",             # ICE BofA MOVE Index (Bond market volatility)\n",
    "    \"OVXCLS\":   \"ovx_oil_vol\",               # CBOE Crude Oil Volatility Index (Oil market volatility)\n",
    "    \"GVZCLS\":   \"gvz_gold_vol\",              # CBOE Gold Volatility Index (Gold market volatility)\n",
    "    \"DTWEXBGS\": \"usd_trade_weighted_index\",  # Trade-Weighted U.S. Dollar Index (Broad Goods)\n",
    "    \"DGS2\":     \"us_2y_treasury_yield\",      # U.S. 2-Year Treasury Yield (constant maturity)\n",
    "    \"DGS10\":    \"us_10y_treasury_yield\",     # U.S. 10-Year Treasury Yield (constant maturity)\n",
    "}\n",
    "\n",
    "# --- REPRODUCABILITY ---\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Utilities: Metrics & Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAE & MASE (predicted vs. realized)\n",
    "def mae(y_true, y_pred):\n",
    "    y_true = pd.Series(y_true).astype(float).values\n",
    "    y_pred = pd.Series(y_pred).astype(float).values\n",
    "    return float(np.mean(np.abs(y_true - y_pred)))\n",
    "\n",
    "def mase(y_true, y_pred):\n",
    "    y_true = pd.Series(y_true).astype(float).values\n",
    "    y_pred = pd.Series(y_pred).astype(float).values\n",
    "    naive = np.roll(y_true, 1)[1:]\n",
    "    err_model = np.abs(y_true[1:] - y_pred[1:]).mean()\n",
    "    err_naive = np.abs(y_true[1:] - naive).mean()\n",
    "    return float(err_model / err_naive) if err_naive > 0 else np.nan\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Data Loading\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API Wrappers\n",
    "CG_BASE = \"https://api.coingecko.com/api/v3\"\n",
    "def cg_universe(top_n=TOP_N, vs_currency=BASE_FIAT):\n",
    "    url = f\"{CG_BASE}/coins/markets\"\n",
    "    params = dict(vs_currency=vs_currency, order=\"market_cap_desc\", per_page=top_n, page=1)\n",
    "    r = requests.get(url, params=params)\n",
    "    return [d[\"id\"] for d in r.json()]\n",
    "\n",
    "def cgpriceactiondaily(coins, days=LOOKBACK_DAYS, vs_currency=BASE_FIAT):\n",
    "    out, idx = {}, None\n",
    "    for cid in coins:\n",
    "        try:\n",
    "            url = f\"{CG_BASE}/coins/{cid}/market_chart\"\n",
    "            params = dict(vs_currency=vs_currency, days=days, interval=\"daily\")\n",
    "            r = requests.get(url, params=params)\n",
    "            js = r.json()\n",
    "            p = pd.DataFrame(js.get(\"prices\", []), columns=[\"ts\", f\"prices_{cid}\"])\n",
    "            v = pd.DataFrame(js.get(\"total_volumes\", []), columns=[\"ts\", f\"total_volumes_{cid}\"])\n",
    "            dfc = pd.merge(p, v, on=\"ts\", how=\"outer\").sort_values(\"ts\")\n",
    "            dfc[\"date\"] = pd.to_datetime(dfc[\"ts\"], unit=\"ms\").dt.tz_localize(\"UTC\").dt.tz_convert(TIMEZONE).dt.date\n",
    "            dfc = dfc.drop(columns=[\"ts\"]).groupby(\"date\").last()\n",
    "            out[cid] = dfc\n",
    "        except Exception as e:\n",
    "            print(f\"Error for {cid}: {e}\")\n",
    "            continue\n",
    "        time.sleep(3)\n",
    "    return pd.concat(out.values(), axis=1, join=\"outer\").sort_index()\n",
    "\n",
    "DERIBIT_BASE = \"https://www.deribit.com/api/v2\"\n",
    "def deribit_dvol_daily_multi(symbols):\n",
    "    frames = []\n",
    "    for sym in symbols:\n",
    "        try:\n",
    "            r = requests.get(\n",
    "                            f\"{DERIBIT_BASE}/public/get_volatility_index_data\", \n",
    "                            params={\"currency\": sym}\n",
    "                        )\n",
    "            js = r.json()\n",
    "            data = js.get(\"result\", js.get(\"data\", {})).get(\"data\", js.get(\"data\", []))\n",
    "            if isinstance(data, dict) and \"data\" in data:\n",
    "                data = data[\"data\"]\n",
    "            if not data: \n",
    "                continue\n",
    "            df = pd.DataFrame(data)\n",
    "            ts_col = \"timestamp\" if \"timestamp\" in df.columns else \"t\" if \"t\" in df.columns else None\n",
    "            val_col = \"value\" if \"value\" in df.columns else \"index\" if \"index\" in df.columns else None\n",
    "            if ts_col is None or val_col is None:\n",
    "                continue\n",
    "            df[\"date\"] = pd.to_datetime(df[ts_col], unit=\"ms\").dt.tz_localize(\"UTC\").dt.tz_convert(TIMEZONE).dt.date\n",
    "            df = df.groupby(\"date\")[val_col].last().to_frame(name=f\"dvol_{sym.lower()}\")\n",
    "            frames.append(df)\n",
    "        except Exception:\n",
    "            continue\n",
    "    return pd.concat(frames, axis=1).sort_index() if frames else pd.DataFrame()\n",
    "\n",
    "DUNE_BASE = \"https://api.dune.com/api/v1\"\n",
    "def dune_metrics_daily(query_ids, api_key=None):\n",
    "    if not query_ids or api_key is None:\n",
    "        return pd.DataFrame()\n",
    "    headers = {\"X-Dune-Api-Key\": api_key}\n",
    "    cols = []\n",
    "    for col_name, qid in query_ids.items():\n",
    "        try:\n",
    "            r = requests.get(f\"{DUNE_BASE}/query/{qid}/results\", headers=headers)\n",
    "            rows = r.json().get(\"result\", {}).get(\"rows\", [])\n",
    "            if not rows: \n",
    "                continue\n",
    "            df = pd.DataFrame(rows)\n",
    "            date_col = next((c for c in [\"date\",\"day\",\"time\",\"ts\",\"timestamp\"] if c in df.columns), df.columns[0])\n",
    "            df[\"date\"] = pd.to_datetime(df[date_col]).dt.tz_localize(None).dt.date\n",
    "            val_col = next((c for c in df.columns if c != \"date\" and pd.api.types.is_numeric_dtype(df[c])), None)\n",
    "            if val_col is None:\n",
    "                for c in df.columns:\n",
    "                    if c != \"date\":\n",
    "                        df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "                        if df[c].notna().any():\n",
    "                            val_col = c; break\n",
    "            if val_col is None: \n",
    "                continue\n",
    "            cols.append(df[[\"date\", val_col]].groupby(\"date\").last().rename(columns={val_col: col_name}))\n",
    "        except Exception:\n",
    "            continue\n",
    "    return pd.concat(cols, axis=1).sort_index() if cols else pd.DataFrame()\n",
    "\n",
    "FRED_BASE = \"https://api.stlouisfed.org/fred/series/observations\"\n",
    "def fetch_fred_series_df(series, api_key=None, start_date= START_DATE):\n",
    "    if not series or api_key is None:\n",
    "        return pd.DataFrame()\n",
    "    frames = []\n",
    "    for fred_id, col_name in series.items():\n",
    "        try:\n",
    "            params = {\"series_id\": fred_id, \"api_key\": api_key, \"file_type\": \"json\", \"observation_start\": START_DATE}\n",
    "            r = requests.get(FRED_BASE, params=params)\n",
    "            obs = r.json().get(\"observations\", [])\n",
    "            if not obs: \n",
    "                continue\n",
    "            df = pd.DataFrame(obs)[[\"date\",\"value\"]]\n",
    "            df[\"date\"] = pd.to_datetime(df[\"date\"]).dt.date\n",
    "            df[\"value\"] = pd.to_numeric(df[\"value\"], errors=\"coerce\")\n",
    "            frames.append(df.groupby(\"date\")[\"value\"].last().to_frame(name=col_name))\n",
    "        except Exception:\n",
    "            continue\n",
    "    return pd.concat(frames, axis=1).sort_index().ffill() if frames else pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Technical Analysis Indicators\n",
    "def compute_ta_indicators(df, price_prefix=\"prices_\", rsi_period=14,\n",
    "                          macd_fast=12, macd_slow=26, macd_signal=9,\n",
    "                          sma_windows=(10,20,50), ema_windows=(10,20,50)):\n",
    "    out = pd.DataFrame(index=df.index)\n",
    "    price_cols = [c for c in df.columns if c.startswith(price_prefix)]\n",
    "    if not price_cols: return out\n",
    "    coins = [c[len(price_prefix):] for c in price_cols]\n",
    "    for coin in coins:\n",
    "        p = pd.to_numeric(df[f\"{price_prefix}{coin}\"], errors=\"coerce\")\n",
    "        out[f\"rsi{rsi_period}_{coin}\"] = talib.RSI(p.values, timeperiod=rsi_period)\n",
    "        macd, macd_sig, macd_hist = talib.MACD(p.values, fastperiod=macd_fast, slowperiod=macd_slow, signalperiod=macd_signal)\n",
    "        out[f\"macd_{coin}\"] = macd; out[f\"macd_signal_{coin}\"] = macd_sig; out[f\"macd_hist_{coin}\"] = macd_hist\n",
    "        for w in sma_windows: out[f\"sma{w}_{coin}\"] = talib.SMA(p.values, timeperiod=w)\n",
    "        for w in ema_windows: out[f\"ema{w}_{coin}\"] = talib.EMA(p.values, timeperiod=w)\n",
    "    out.index = df.index\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  GARCH(1,1) & HAR-RV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HAR & GARCH\n",
    "def fit_garch_11(returns, scale=100.0):\n",
    "    r = returns.dropna().astype(float) * scale\n",
    "    am = arch_model(r, mean=\"Zero\", vol=\"GARCH\", p=1, q=1, dist=\"normal\")\n",
    "    return am.fit(disp=\"off\")\n",
    "def forecast_garch_rolling(returns, train_size, scale=100.0, refit_every=0):\n",
    "    r = returns.dropna().astype(float); idx=r.index; n=len(r)\n",
    "    preds, pred_idx, last_refit, res = [], [], -1, None\n",
    "    for t in range(train_size, n):\n",
    "        if (res is None) or (refit_every==0) or ((t-last_refit)>=refit_every):\n",
    "            res = fit_garch_11(r.iloc[:t], scale=scale); last_refit = t\n",
    "        var_next = res.forecast(horizon=1).variance.iloc[-1,0]\n",
    "        preds.append(float(np.sqrt(var_next))/scale); pred_idx.append(idx[t])\n",
    "    return pd.Series(preds, index=pred_idx, name=\"garch11_vol_pred\")\n",
    "def _har_features(rv):\n",
    "    rv = rv.astype(float)\n",
    "    return pd.DataFrame({\"RV1\": rv.shift(1), \"RV5\": rv.shift(1).rolling(5).mean(), \"RV22\": rv.shift(1).rolling(22).mean()})\n",
    "def fit_har_ols(rv_train):\n",
    "    X = _har_features(rv_train); y = rv_train\n",
    "    df = pd.concat([X, y.rename(\"y\")], axis=1).dropna()\n",
    "    model = sm.OLS(df[\"y\"], sm.add_constant(df[[\"RV1\",\"RV5\",\"RV22\"]])).fit()\n",
    "    p = model.params.to_dict()\n",
    "    return {\"const\": p.get(\"const\",0.0), \"RV1\": p[\"RV1\"], \"RV5\": p[\"RV5\"], \"RV22\": p[\"RV22\"]}\n",
    "def forecast_har(rv, params, start_idx):\n",
    "    rv = rv.astype(float); idx = rv.index; n=len(rv); preds=[]\n",
    "    for t in range(start_idx, n):\n",
    "        rv1 = rv.iloc[t-1] if t-1>=0 else np.nan\n",
    "        rv5 = rv.iloc[max(0,t-5):t].mean()\n",
    "        rv22 = rv.iloc[max(0,t-22):t].mean()\n",
    "        preds.append(float(np.dot([1.0, rv1, rv5, rv22], [params[\"const\"], params[\"RV1\"], params[\"RV5\"], params[\"RV22\"]])))\n",
    "    return pd.Series(preds, index=idx[start_idx:], name=\"har_vol_pred\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  LSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM\n",
    "def make_univariate_sequences(series, seq_len):\n",
    "    v = series.dropna().astype(float).values\n",
    "    X, y = [], []\n",
    "    for i in range(len(v)-seq_len):\n",
    "        X.append(v[i:i+seq_len]); y.append(v[i+seq_len])\n",
    "    return np.asarray(X,float).reshape(-1,seq_len,1), np.asarray(y,float)\n",
    "def build_lstm_model(input_shape, units=64, dropout=0.0):\n",
    "    m = Sequential(); m.add(LSTM(units, input_shape=input_shape))\n",
    "    if dropout>0: m.add(Dropout(dropout))\n",
    "    m.add(Dense(1)); m.compile(optimizer=\"adam\", loss=\"mse\"); return m\n",
    "def train_lstm(model, X_train, y_train, epochs=25, batch_size=16, validation_split=0.1, patience=5):\n",
    "    cb=[EarlyStopping(monitor=\"val_loss\", patience=patience, restore_best_weights=True)] if validation_split and patience else []\n",
    "    return model.fit(X_train,y_train,epochs=epochs,batch_size=batch_size,validation_split=validation_split,callbacks=cb,verbose=0,shuffle=False)\n",
    "def predict_lstm(model, X_seq): return model.predict(X_seq, verbose=0).reshape(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "coins = cg_universe(TOP_N, vs_currency=BASE_FIAT)\n",
    "O = cgpriceactiondaily(coins, days=LOOKBACK_DAYS, vs_currency=BASE_FIAT)\n",
    "D_dvol = deribit_dvol_daily_multi(['BTC','ETH'])\n",
    "# U_dune = dune_metrics_daily(DUNE_QUERIES, DUNE_API_KEY) \n",
    "U_dune= pd.read_csv(DUNE_CSV_PATH).set_index('date')\n",
    "U_dune.index =pd.to_datetime(U_dune.index)   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_fred = fetch_fred_series_df(FRED_KNOWN, FRED_API_KEY, START_DATE)   \n",
    "df = O.copy()\n",
    "for extra in [D_dvol, U_dune, M_fred]:\n",
    "    if extra is not None and not extra.empty:\n",
    "        df = df.join(extra, how=\"outer\")\n",
    "df = df.sort_index().ffill().dropna(how=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prices_bitcoin</th>\n",
       "      <th>total_volumes_bitcoin</th>\n",
       "      <th>prices_ethereum</th>\n",
       "      <th>total_volumes_ethereum</th>\n",
       "      <th>prices_tether</th>\n",
       "      <th>total_volumes_tether</th>\n",
       "      <th>prices_ripple</th>\n",
       "      <th>total_volumes_ripple</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-09-27</th>\n",
       "      <td>65130.768840</td>\n",
       "      <td>3.799557e+10</td>\n",
       "      <td>2630.949837</td>\n",
       "      <td>1.668616e+10</td>\n",
       "      <td>1.000071</td>\n",
       "      <td>6.199968e+10</td>\n",
       "      <td>0.590002</td>\n",
       "      <td>1.320296e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-09-28</th>\n",
       "      <td>65791.002125</td>\n",
       "      <td>3.266492e+10</td>\n",
       "      <td>2698.192821</td>\n",
       "      <td>1.646812e+10</td>\n",
       "      <td>1.000440</td>\n",
       "      <td>3.959733e+10</td>\n",
       "      <td>0.589115</td>\n",
       "      <td>1.401604e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-09-29</th>\n",
       "      <td>65934.107094</td>\n",
       "      <td>1.534291e+10</td>\n",
       "      <td>2680.218702</td>\n",
       "      <td>9.607073e+09</td>\n",
       "      <td>1.000640</td>\n",
       "      <td>2.389775e+10</td>\n",
       "      <td>0.615009</td>\n",
       "      <td>2.770313e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-09-30</th>\n",
       "      <td>65663.689867</td>\n",
       "      <td>1.294871e+10</td>\n",
       "      <td>2659.611212</td>\n",
       "      <td>9.570811e+09</td>\n",
       "      <td>0.999926</td>\n",
       "      <td>3.519751e+10</td>\n",
       "      <td>0.642592</td>\n",
       "      <td>2.594473e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-01</th>\n",
       "      <td>63243.275325</td>\n",
       "      <td>3.512445e+10</td>\n",
       "      <td>2597.341152</td>\n",
       "      <td>1.753926e+10</td>\n",
       "      <td>1.000155</td>\n",
       "      <td>6.021731e+10</td>\n",
       "      <td>0.611934</td>\n",
       "      <td>2.572234e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-09-22</th>\n",
       "      <td>115304.479994</td>\n",
       "      <td>1.865911e+10</td>\n",
       "      <td>4452.871130</td>\n",
       "      <td>1.591068e+10</td>\n",
       "      <td>1.000400</td>\n",
       "      <td>5.412936e+10</td>\n",
       "      <td>2.973350</td>\n",
       "      <td>2.935908e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-09-23</th>\n",
       "      <td>112696.741017</td>\n",
       "      <td>6.915234e+10</td>\n",
       "      <td>4199.951774</td>\n",
       "      <td>5.298809e+10</td>\n",
       "      <td>1.000815</td>\n",
       "      <td>1.486343e+11</td>\n",
       "      <td>2.851139</td>\n",
       "      <td>9.546312e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-09-24</th>\n",
       "      <td>112022.165879</td>\n",
       "      <td>4.615488e+10</td>\n",
       "      <td>4166.190550</td>\n",
       "      <td>2.990268e+10</td>\n",
       "      <td>1.000206</td>\n",
       "      <td>9.586917e+10</td>\n",
       "      <td>2.829056</td>\n",
       "      <td>5.177734e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-09-25</th>\n",
       "      <td>113320.569085</td>\n",
       "      <td>4.667754e+10</td>\n",
       "      <td>4148.656828</td>\n",
       "      <td>2.998892e+10</td>\n",
       "      <td>1.000336</td>\n",
       "      <td>9.576239e+10</td>\n",
       "      <td>2.928589</td>\n",
       "      <td>6.006922e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-09-26</th>\n",
       "      <td>109388.049350</td>\n",
       "      <td>7.258446e+10</td>\n",
       "      <td>3933.452315</td>\n",
       "      <td>5.562524e+10</td>\n",
       "      <td>1.000741</td>\n",
       "      <td>1.538741e+11</td>\n",
       "      <td>2.746123</td>\n",
       "      <td>9.081202e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>365 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            prices_bitcoin  total_volumes_bitcoin  prices_ethereum  \\\n",
       "date                                                                 \n",
       "2024-09-27    65130.768840           3.799557e+10      2630.949837   \n",
       "2024-09-28    65791.002125           3.266492e+10      2698.192821   \n",
       "2024-09-29    65934.107094           1.534291e+10      2680.218702   \n",
       "2024-09-30    65663.689867           1.294871e+10      2659.611212   \n",
       "2024-10-01    63243.275325           3.512445e+10      2597.341152   \n",
       "...                    ...                    ...              ...   \n",
       "2025-09-22   115304.479994           1.865911e+10      4452.871130   \n",
       "2025-09-23   112696.741017           6.915234e+10      4199.951774   \n",
       "2025-09-24   112022.165879           4.615488e+10      4166.190550   \n",
       "2025-09-25   113320.569085           4.667754e+10      4148.656828   \n",
       "2025-09-26   109388.049350           7.258446e+10      3933.452315   \n",
       "\n",
       "            total_volumes_ethereum  prices_tether  total_volumes_tether  \\\n",
       "date                                                                      \n",
       "2024-09-27            1.668616e+10       1.000071          6.199968e+10   \n",
       "2024-09-28            1.646812e+10       1.000440          3.959733e+10   \n",
       "2024-09-29            9.607073e+09       1.000640          2.389775e+10   \n",
       "2024-09-30            9.570811e+09       0.999926          3.519751e+10   \n",
       "2024-10-01            1.753926e+10       1.000155          6.021731e+10   \n",
       "...                            ...            ...                   ...   \n",
       "2025-09-22            1.591068e+10       1.000400          5.412936e+10   \n",
       "2025-09-23            5.298809e+10       1.000815          1.486343e+11   \n",
       "2025-09-24            2.990268e+10       1.000206          9.586917e+10   \n",
       "2025-09-25            2.998892e+10       1.000336          9.576239e+10   \n",
       "2025-09-26            5.562524e+10       1.000741          1.538741e+11   \n",
       "\n",
       "            prices_ripple  total_volumes_ripple  \n",
       "date                                             \n",
       "2024-09-27       0.590002          1.320296e+09  \n",
       "2024-09-28       0.589115          1.401604e+09  \n",
       "2024-09-29       0.615009          2.770313e+09  \n",
       "2024-09-30       0.642592          2.594473e+09  \n",
       "2024-10-01       0.611934          2.572234e+09  \n",
       "...                   ...                   ...  \n",
       "2025-09-22       2.973350          2.935908e+09  \n",
       "2025-09-23       2.851139          9.546312e+09  \n",
       "2025-09-24       2.829056          5.177734e+09  \n",
       "2025-09-25       2.928589          6.006922e+09  \n",
       "2025-09-26       2.746123          9.081202e+09  \n",
       "\n",
       "[365 rows x 8 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "O.dropna(axis=1, thresh=int(0.1*(len(O))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ta_df = compute_ta_indicators(df, price_prefix=\"prices_\", sma_windows=SMA_WINDOWS, ema_windows=EMA_WINDOWS)\n",
    "df = df.join(ta_df).dropna()\n",
    "\n",
    "df[f\"log_returns_{TARGET_COIN}\"] = np.log(df[f\"prices_{TARGET_COIN}\"]).diff()\n",
    "df[f\"realized_vol_{TARGET_COIN}\"] = df[f\"log_returns_{TARGET_COIN}\"].abs()\n",
    "\n",
    "X_full = df.diff().dropna()\n",
    "y_full = df[f\"realized_vol_{TARGET_COIN}\"].shift(-1).dropna()\n",
    "common = X_full.index.intersection(y_full.index)\n",
    "X_full = X_full.loc[common]; y_full = y_full.loc[common]\n",
    "\n",
    "split = int(TRAIN_SPLIT * len(X_full))\n",
    "X_train, X_test = X_full.iloc[:split], X_full.iloc[split:]\n",
    "y_train, y_test = y_full.iloc[:split], y_full.iloc[split:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "returns = df[f\"log_returns_{TARGET_COIN}\"].loc[y_full.index].dropna()\n",
    "train_size_r = int(TRAIN_SPLIT * len(returns))\n",
    "garch_preds = forecast_garch_rolling(returns, train_size=train_size_r, scale=GARCH_SCALE, refit_every=GARCH_REFIT_EVERY)\n",
    "garch_preds = garch_preds.reindex(y_test.index).dropna()\n",
    "print(\"GARCH MAE:\", round(mae(y_test.loc[garch_preds.index], garch_preds), 6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rv = df[f\"realized_vol_{TARGET_COIN}\"].loc[y_full.index].dropna()\n",
    "har_params = fit_har_ols(rv.iloc[:split])\n",
    "har_preds = forecast_har(rv, har_params, start_idx=split).reindex(y_test.index).dropna()\n",
    "print(\"HAR MAE:\", round(mae(y_test.loc[har_preds.index], har_preds), 6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rv_all = df[f\"realized_vol_{TARGET_COIN}\"].loc[y_full.index]\n",
    "rv_tr, rv_te = rv_all.iloc[:split], rv_all.iloc[split:]\n",
    "X_tr_seq, y_tr_seq = make_univariate_sequences(rv_tr, seq_len=SEQ_LEN)\n",
    "X_te_seq, y_te_seq = make_univariate_sequences(pd.concat([rv_tr.iloc[-SEQ_LEN:], rv_te]), seq_len=SEQ_LEN)\n",
    "model = build_lstm_model(input_shape=(SEQ_LEN,1), units=LSTM_UNITS, dropout=0.0)\n",
    "_ = train_lstm(model, X_tr_seq, y_tr_seq, epochs=LSTM_EPOCHS, batch_size=LSTM_BATCH, validation_split=0.1, patience=5)\n",
    "lstm_preds = predict_lstm(model, X_te_seq)\n",
    "y_align = y_test.iloc[len(y_test)-len(lstm_preds):]\n",
    "print(\"LSTM MAE:\", round(mae(y_align, lstm_preds), 6))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VF.venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
